# Web_Scrapping
 Web scraping tasks using Python, BeautifulSoup, and requests, with features for data extraction, cleaning, and storage in various formats.

<img src="https://github.com/rpjinu/Web_Scrapping/blob/main/web-scraping.png" width="1200">

# list of popular Python libraries commonly used for web scraping:-\

1.Requests: Handles HTTP requests, making it easy to send GET, POST, and other requests to websites.\
2.BeautifulSoup: Parses HTML and XML documents, allowing for easy navigation and data extraction from web pages.\
3.Selenium: Automates web browsers to interact with dynamic content rendered by JavaScript.\
4.Scrapy: A powerful web scraping and crawling framework for large-scale scraping tasks.\
5.lxml: A library for parsing HTML and XML documents with a focus on speed and flexibility.\
6.Pandas: Although not a web scraping library, it's commonly used for data manipulation and cleaning after scraping.\
7.Regex (re): For advanced text pattern matching and extraction.\
8.Tesseract-OCR: Used in conjunction with libraries like OpenCV for scraping text from images.\
9.json: For handling and storing JSON data, often used when dealing with APIs.\
10.time: For adding delays between requests to avoid overwhelming servers.\
11.retries: For handling retries on failed HTTP requests to make your scraper more robust.

<img src="" width="1200">
